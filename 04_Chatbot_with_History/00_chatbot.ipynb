{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9d63a4f",
   "metadata": {},
   "source": [
    "# Building A Chatbot with History\n",
    "\n",
    "the chatbot able to have a conversation and remember previous interactions \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34ca1430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x72ef0a9e2680>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x72ef0a824910>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(\n",
    "    model=\"gemma2-9b-it\",\n",
    "    api_key=groq_api_key,\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5d43657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage \n",
    "# model.invoke() # -> This message go to ai model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c75e72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Omkar. ðŸ˜Š  \\n\\nIt's nice to meet you, Omkar. What can I help you with today?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 45, 'total_tokens': 76, 'completion_time': 0.056363636, 'prompt_time': 0.003615794, 'queue_time': 0.256309855, 'total_time': 0.05997943}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--61bdec8f-8eb3-44fa-9b93-690aff19d1e2-0', usage_metadata={'input_tokens': 45, 'output_tokens': 31, 'total_tokens': 76})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke([HumanMessage(content=\"Hello my name is omkar i am a Ai engineering student\"),\n",
    "           AIMessage(content=\"Hello Omkar, nice to meet you!\"),\n",
    "           HumanMessage(content=\"What is my name?\"),]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41116250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message History \n",
    "# we can use message history class to wrap our model and make it stateful , it keep the track of input and output of the model , and store it into datastore , Future interactions will then load those messages and pass them into the chain as part of the input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "841a56b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "\n",
    "store  = {}\n",
    "def get_session_history(session_id : str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    model,\n",
    "    get_session_history\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad146500",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat1\"}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c47e48e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hello my name is omkar i am a Ai engineering student\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f139a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Omkar!\\n\\nThat's great to know!  AI engineering is a fascinating field. What are you most interested in learning about or working on within AI?  \\n\\nI'm happy to chat about anything related to AI, or just have a general conversation.\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a55620e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Omkar.  \\n\\nYou told me at the beginning of our conversation! ðŸ˜Š  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 92, 'total_tokens': 115, 'completion_time': 0.041818182, 'prompt_time': 0.00533136, 'queue_time': 0.249513349, 'total_time': 0.047149542}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--6dfea41e-130b-4734-b493-afde53a1326f-0', usage_metadata={'input_tokens': 92, 'output_tokens': 23, 'total_tokens': 115})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93a3a0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As an AI, I have no memory of past conversations and do not know your name. Can you tell me? ðŸ˜Š\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Change the config it cant remember \n",
    "config1 = {\"configurable\": {\"session_id\": \"chat2\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51199230",
   "metadata": {},
   "source": [
    "# Prompt Templates \n",
    "\n",
    "### prompt templates help to turn raw user info into a format that llm can work with , "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1712204d",
   "metadata": {},
   "source": [
    "#### if raw is  just a message then it make more complicated first and then add in a system message with some custom instriction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea9b92f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. Answer all question to the  nest of your ability.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67677f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c98bb34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Omkar, it's nice to meet you! \\n\\nI understand you're an AI Engineering student. That's fascinating! What are you currently working on or interested in learning more about within AI engineering? \\n\\nI'm here to help in any way I can. Whether you have questions about specific concepts, need help brainstorming ideas, or just want to discuss the latest advancements in AI, feel free to ask.  \\n\\nLet's explore the world of AI together! ðŸ˜Š\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 104, 'prompt_tokens': 38, 'total_tokens': 142, 'completion_time': 0.189090909, 'prompt_time': 0.002403995, 'queue_time': 0.25409322500000003, 'total_time': 0.191494904}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--b1e71afa-6b47-4cd6-80bf-91fe43366ac3-0', usage_metadata={'input_tokens': 38, 'output_tokens': 104, 'total_tokens': 142})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hello my name is omkar i am a Ai engineering student\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58e7b092",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba224e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Omkar! It's great to meet you. As an AI engineering student, you're diving into a fascinating field. \\n\\nWhat can I help you with today? \\n\\nAre you working on a particular project? Do you have any questions about AI concepts? Or perhaps you'd like to discuss the latest advancements in the field? \\n\\nI'm here to assist in any way I can. ðŸ˜Š  \\n\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat3\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hello my name is omkar i am a Ai engineering student\")],\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31c10863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'à¤¨à¤®à¤¸à¥à¤¤à¥‡ à¤“à¤®à¤•à¤¾à¤°! \\n\\nà¤®à¥ˆà¤‚ à¤†à¤ªà¤•à¥€ à¤®à¤¦à¤¦ à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤¤à¥ˆà¤¯à¤¾à¤° à¤¹à¥‚à¤à¥¤ à¤à¤†à¤‡ à¤‡à¤‚à¤œà¥€à¤¨à¤¿à¤¯à¤°à¤¿à¤‚à¤— à¤®à¥‡à¤‚ à¤ªà¤¢à¤¼à¤¾à¤ˆ à¤•à¤°à¤¨à¤¾ à¤•à¤¿à¤¤à¤¨à¤¾ à¤°à¥‹à¤®à¤¾à¤‚à¤šà¤• à¤¹à¥ˆ! \\n\\nà¤†à¤ªà¤•à¥‡ à¤•à¤¿à¤¸à¥€ à¤­à¥€ à¤ªà¥à¤°à¤¶à¥à¤¨ à¤•à¥‡ à¤²à¤¿à¤ à¤®à¥ˆà¤‚ à¤¯à¤¹à¤¾à¤ à¤¹à¥‚à¤à¥¤ \\n\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Add more complexity \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. Answer all question to the  nest of your ability in this {language}.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model\n",
    "response = chain.invoke({\n",
    "    \"messages\":[HumanMessage(content=\"Hello my name is omkar i am a Ai engineering student\")],\n",
    "    \"language\":\"Hindi\"\n",
    "})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d059bdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61db8ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'à¤¨à¤®à¤¸à¥à¤¤à¥‡ à¤“à¤®à¤•à¤¾à¤°! ðŸ˜Š\\n\\nà¤¯à¤¹ à¤œà¤¾à¤¨à¤•à¤° à¤¬à¤¹à¥à¤¤ à¤–à¥à¤¶à¥€ à¤¹à¥à¤ˆà¥¤ à¤¤à¥à¤® à¤à¤†à¤ˆ à¤‡à¤‚à¤œà¥€à¤¨à¤¿à¤¯à¤°à¤¿à¤‚à¤— à¤®à¥‡à¤‚ à¤ªà¤¢à¤¼à¤¾à¤ˆ à¤•à¤° à¤°à¤¹à¥‡ à¤¹à¥‹!  à¤•à¥Œà¤¨ à¤¸à¤¾ à¤µà¤¿à¤·à¤¯ à¤¤à¥à¤®à¥à¤¹à¥‡à¤‚ à¤¸à¤¬à¤¸à¥‡ à¤œà¥à¤¯à¤¾à¤¦à¤¾ à¤ªà¤¸à¤‚à¤¦ à¤¹à¥ˆ? \\n\\nà¤®à¥ˆà¤‚ à¤¤à¥à¤®à¥à¤¹à¤¾à¤°à¥€ à¤®à¤¦à¤¦ à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤¤à¥ˆà¤¯à¤¾à¤° à¤¹à¥‚à¤à¥¤  \\n\\nà¤•à¥à¤¯à¤¾ à¤¤à¥à¤® à¤•à¥‹à¤ˆ à¤¸à¤µà¤¾à¤² à¤ªà¥‚à¤›à¤¨à¤¾ à¤šà¤¾à¤¹à¤¤à¥‡ à¤¹à¥‹? \\n\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat4\"}}\n",
    "response = with_message_history.invoke(\n",
    "   {\n",
    "       \"messages\": [HumanMessage(content=\"Hello my name is omkar i am a Ai engineering student\")],\n",
    "       \"language\": \"Hindi\",\n",
    "   }\n",
    "   , config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f702cb",
   "metadata": {},
   "source": [
    "## Manage the conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a8ca07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if unmanaged the list of messages will grow unbounded and potentially overflow the context windows of the LLM.so we add the step the size of the context window\n",
    "\n",
    "\n",
    "# trim_message -> it allow us to specify how many tokens we want to keep in the message history, and it will automatically trim the messages to fit within that limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53777826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant. Answer all question to the  nest of your ability in this Hindi.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hello my name is omkar i am a Ai engineering student', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello Omkar, nice to meet you!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Your name is Omkar.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='How are you?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='I am doing well, thank you for asking!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is the weather today?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The weather today is sunny.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=1000,  # specify the maximum number of tokens to keep\n",
    "    strategy=\"last\",  # specify the strategy to use\n",
    "    token_counter=model,\n",
    "    include_system =True,  # include system messages in the trimming\n",
    "    allow_partial=False,  \n",
    "    start_on = \"human\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant. Answer all question to the  nest of your ability in this Hindi.\"),\n",
    "    HumanMessage(content=\"Hello my name is omkar i am a Ai engineering student\"),\n",
    "    AIMessage(content=\"Hello Omkar, nice to meet you!\"),\n",
    "    HumanMessage(content=\"What is my name?\"),\n",
    "    AIMessage(content=\"Your name is Omkar.\"),\n",
    "    HumanMessage(content=\"How are you?\"),\n",
    "    AIMessage(content=\"I am doing well, thank you for asking!\"),\n",
    "    HumanMessage(content=\"What is the weather today?\"),\n",
    "    AIMessage(content=\"The weather today is sunny.\"),\n",
    "]\n",
    "\n",
    "trimmed_messages = trimmer.invoke(messages)\n",
    "trimmed_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0acaba40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'à¤†à¤ªà¤•à¤¾ à¤¨à¤¾à¤® à¤“à¤®à¤•à¤¾à¤° à¤¹à¥ˆà¥¤  \\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        messages=itemgetter(\"messages\") | trimmer # Extract the messages from the input\n",
    "    )\n",
    "    | prompt\n",
    "    | model\n",
    "\n",
    ")\n",
    "\n",
    "response  = chain.invoke({\n",
    "    \"messages\": messages + [HumanMessage(content=\"What is my name?\")],\n",
    "    \"language\": \"Hindi\",\n",
    "})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7141fbad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'à¤†à¤ªà¤•à¤¾ à¤¨à¤¾à¤® Omkar à¤¹à¥ˆà¥¤  \\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets wrarp this in the message History \n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")\n",
    "config = {\"configurable\": {\"session_id\": \"chat6\"}}\n",
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"What is my name?\")],\n",
    "        \"language\": \"Hindi\",\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883c1fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
