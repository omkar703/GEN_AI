{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf23696a",
   "metadata": {},
   "source": [
    "# Getting started with Langchain And Open AI \n",
    "\n",
    "  1. Langchain , Langsmith , LangServe\n",
    "  2. basic components of Langchain\n",
    "  3. Simple application of Langchain \n",
    "  4. Trace application with langsmith \n",
    "  5. serve application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1186965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7a6d7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x76eab1f57370> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x76eab1f57e80> root_client=<openai.OpenAI object at 0x76ead0af7a90> root_async_client=<openai.AsyncOpenAI object at 0x76eab1f56ad0> model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "print(llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7599a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.invoke(\"What is the capital of India?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4da8aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The capital of India is New Delhi.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 14, 'total_tokens': 22, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-Bcv1ckT6OTqNBo6XFZOa3Ys0qBwnR', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--cb161a5f-fb86-4f98-9e61-6cb0007bf53f-0' usage_metadata={'input_tokens': 14, 'output_tokens': 8, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4abc6248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Give me in one world answer.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Templates \n",
    "from langchain.prompts import ChatPromptTemplate ## tell llm model that behave like this\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Give me in one world answer.\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c164424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Delhi' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 25, 'total_tokens': 27, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BcvI0bPlBCutEqTZfrCwAgbCbzymP', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--d15e674f-32fd-4d44-b464-eeb7e6179d87-0' usage_metadata={'input_tokens': 25, 'output_tokens': 2, 'total_tokens': 27, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "result = chain.invoke({\"input\": \"What is the capital of India?\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94ad6c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49773ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delhi\n"
     ]
    }
   ],
   "source": [
    "## Stringoutput Parser \n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()\n",
    "chain = prompt | llm | parser\n",
    "result = chain.invoke({\"input\": \"What is the capital of India?\"})\n",
    "print(result)\n",
    "# direct answer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cff289c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
